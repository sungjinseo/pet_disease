{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420cfab8-b8d3-4d20-9c2d-1d5cadcdbfec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "\n",
    "from torch.optim.adam import Adam\n",
    "from modules.pytorchtools import EarlyStopping # 위 링크의 깃허브 파일에서 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85910ff-35c6-49d3-a1fb-29fad81b4df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # 1.합성곱층 정의\n",
    "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        # 2.배치 정규화층 정의\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 3.스킵 커넥션을 위해 초기 입력을 저장\n",
    "        x_ = x\n",
    "\n",
    "        x = self.c1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # 4.합성곱의 결과와 입력의 채널 수를 맞춤\n",
    "        x_ = self.downsample(x_)\n",
    "\n",
    "        # 5.합성곱층의 결과와 저장해놨던 입력값을 더해줌\n",
    "        x += x_\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c751dbb0-6d42-41e6-ba1e-47cccd20d560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        #Output Size = (W - F + 2P) / S + 1\n",
    "        #W: input_volume_size\n",
    "        #F: kernel_size\n",
    "        #P: padding_size\n",
    "        #S: strides\n",
    "        #nn.Conv2d(in_channels=3, out_channels=32, kernel=3, padding=1)\n",
    "        #output_size = (32 - 3 + 2*1) / 1 + 1 = 32\n",
    "\n",
    "        # ❶ 기본 블록\n",
    "        # 기본 입력이 RGB인 3채널\n",
    "        self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
    "        self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
    "        self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
    "\n",
    "\n",
    "        # ❷ 풀링을 최댓값이 아닌 평균값으로\n",
    "        # maxpooling=2\n",
    "        #input_filter_size/2 = output_filter_size\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # ❸ 분류기  MLP\n",
    "        # 4 * 4* 256\n",
    "        # out_feature * kerner\n",
    "        # (batchsize/2) * imgsize\n",
    "        # 4 * 224 * 224\n",
    "        #self.fc1 = nn.Linear(in_features= 4 * 128 * 128, out_features=2048)\n",
    "        self.fc1 = nn.Linear(in_features=4 * 64 * 64, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # 1. 기본 블록과 풀링층을 통과\n",
    "        x = self.b1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "\n",
    "        # ❷ 분류기의 입력으로 사용하기 위해 flatten\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "        # ❸ 분류기로 예측값 출력\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95765c79-debf-4d85-b6c1-54bbea9ec791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1024x1024 resize train / meanR=0.43303847, meanG=0.4034577, meanB=0.39415097  / stdR=0.18344551, stdG=0.17549995, stdB=0.1647388   \n",
    "# 128x128 resize train / meanR=0.43305725, meanG=0.40347522, meanB=0.3941705  / stdR=0.17281055, stdG=0.16584247, stdB=0.15571058 \n",
    "# 244 평균 0.27763095, 0.22682726, 0.2020654\n",
    "# 표준편차 0.23883308, 0.21106692, 0.20242342\n",
    "\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def create_datasets(data_dir, batch_size):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        #transforms.RandomHorizontalFlip(),  # 좌우반전 \n",
    "        #transforms.RandomVerticalFlip(),  # 상하반전 \n",
    "        #transforms.Resize(32),  # 알맞게 변경하세요 \n",
    "        transforms.Resize(64),  # 알맞게 변경하세요 \n",
    "        transforms.CenterCrop()\n",
    "        transforms.ToTensor(),  # 이 과정에서 [0, 255]의 범위를 갖는 값들을 [0.0, 1.0]으로 정규화, torch.FloatTensor로 변환\n",
    "        transforms.Normalize([0.2749446, 0.22524835, 0.20173368], [0.2369616, 0.21033151, 0.20125428])  #  정규화(normalization)\n",
    "    ])\n",
    "    \n",
    "    # test_transform = transforms.Compose([   # 나중에 test 데이터 불러올 때 참고하세요. \n",
    "    #     transforms.Resize(224),\n",
    "    #     transforms.ToTensor(), # 이 과정에서 [0, 255]의 범위를 갖는 값들을 [0.0, 1.0]으로 정규화 \n",
    "    #     transforms.Normalize([0.2749446, 0.22524835, 0.20173368], [0.2369616, 0.21033151, 0.20125428])  # 테스트 데이터로 계산을 진행해서 따로 지정해주어도 좋습니다\n",
    "    # ])\n",
    "\n",
    "    # choose the training and test datasets\n",
    "    train_data = datasets.ImageFolder(os.path.join(data_dir, 'train'), train_transform)\n",
    "\n",
    "    # trainning set 중 validation 데이터로 사용할 비율\n",
    "    valid_size = 0.2\n",
    "\n",
    "    # validation으로 사용할 trainning indices를 얻는다.\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # trainning, validation batch를 얻기 위한 sampler정의\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # load training data in batches\n",
    "    train_loader = DataLoader(train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               sampler=train_sampler,\n",
    "                               num_workers=4)\n",
    "\n",
    "    # load validation data in batches\n",
    "    valid_loader = DataLoader(train_data,\n",
    "                               batch_size=batch_size,\n",
    "                               sampler=valid_sampler,\n",
    "                               num_workers=4)\n",
    "\n",
    "    return train_data, train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c581426-bd09-45af-b48f-2963ff9e58cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '/home/jupyter/workspace/eyes'\n",
    "bs = 4\n",
    "train_data, train_loader, valid_loader = create_datasets(root_dir, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bac35fa-80cd-457f-9e50-6a9d19d68878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (b1): BasicBlock(\n",
       "    (c1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (b2): BasicBlock(\n",
       "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (b3): BasicBlock(\n",
       "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (downsample): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=16384, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=11, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ResNet(num_classes=len(train_data.classes))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ff56448-272c-4233-94bc-07f62c1d4499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:1 loss:2.072284460067749: 100% 332/332 [00:08<00:00, 39.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 681.556140).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:2 loss:2.5176048278808594: 100% 332/332 [00:08<00:00, 40.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (681.556140 --> 596.854130).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:3 loss:1.233520269393921: 100% 332/332 [00:08<00:00, 40.05it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (596.854130 --> 567.377951).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:4 loss:1.108485460281372: 100% 332/332 [00:08<00:00, 40.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (567.377951 --> 535.135961).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:5 loss:2.1931777000427246: 100% 332/332 [00:08<00:00, 40.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (535.135961 --> 498.021542).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:6 loss:1.5078248977661133: 100% 332/332 [00:08<00:00, 40.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (498.021542 --> 458.394354).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:7 loss:1.1395618915557861: 100% 332/332 [00:08<00:00, 40.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (458.394354 --> 413.462073).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:8 loss:1.6435188055038452: 100% 332/332 [00:08<00:00, 40.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (413.462073 --> 358.303348).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:9 loss:1.4730732440948486: 100% 332/332 [00:08<00:00, 40.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (358.303348 --> 304.615380).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:10 loss:1.1742291450500488: 100% 332/332 [00:08<00:00, 40.93it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (304.615380 --> 238.349153).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:11 loss:0.4617367088794708: 100% 332/332 [00:08<00:00, 40.31it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (238.349153 --> 173.849720).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:12 loss:0.12700246274471283: 100% 332/332 [00:08<00:00, 40.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (173.849720 --> 131.561268).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:13 loss:0.1756647527217865: 100% 332/332 [00:08<00:00, 41.04it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (131.561268 --> 87.937545).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:14 loss:0.25799286365509033: 100% 332/332 [00:08<00:00, 40.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (87.937545 --> 74.479561).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:15 loss:0.03681771457195282: 100% 332/332 [00:08<00:00, 40.42it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (74.479561 --> 51.938464).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:16 loss:0.04914965108036995: 100% 332/332 [00:08<00:00, 40.46it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (51.938464 --> 35.422790).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:17 loss:0.1303458958864212: 100% 332/332 [00:08<00:00, 40.43it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:18 loss:0.4722702205181122: 100% 332/332 [00:08<00:00, 41.00it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:19 loss:0.04843346029520035: 100% 332/332 [00:08<00:00, 40.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:20 loss:0.0250473041087389: 100% 332/332 [00:08<00:00, 40.94it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (35.422790 --> 27.604664).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:21 loss:0.03305383399128914: 100% 332/332 [00:08<00:00, 40.59it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:22 loss:0.05096730589866638: 100% 332/332 [00:08<00:00, 41.02it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:23 loss:0.01929621398448944: 100% 332/332 [00:08<00:00, 40.59it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:24 loss:0.8190957903862: 100% 332/332 [00:08<00:00, 40.70it/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (27.604664 --> 25.179682).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:25 loss:0.0023306608200073242: 100% 332/332 [00:08<00:00, 40.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (25.179682 --> 20.355664).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:26 loss:0.011001018807291985: 100% 332/332 [00:08<00:00, 41.10it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (20.355664 --> 19.351472).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:27 loss:0.004277640953660011: 100% 332/332 [00:07<00:00, 42.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (19.351472 --> 17.624122).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:28 loss:0.000777239678427577: 100% 332/332 [00:07<00:00, 42.20it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (17.624122 --> 12.513732).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:29 loss:1.2237168550491333: 100% 332/332 [00:07<00:00, 41.59it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (12.513732 --> 10.799084).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:30 loss:0.05033280700445175: 100% 332/332 [00:08<00:00, 37.39it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:31 loss:0.01196286454796791: 100% 332/332 [00:07<00:00, 41.58it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:32 loss:0.9537715315818787: 100% 332/332 [00:07<00:00, 42.08it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:33 loss:8.621299639344215e-05: 100% 332/332 [00:07<00:00, 41.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:34 loss:0.0034032792318612337: 100% 332/332 [00:07<00:00, 42.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:35 loss:0.0034319283440709114: 100% 332/332 [00:07<00:00, 42.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:36 loss:1.3306028842926025: 100% 332/332 [00:07<00:00, 42.20it/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:37 loss:0.006795079912990332: 100% 332/332 [00:07<00:00, 42.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (10.799084 --> 8.614323).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:38 loss:0.0010131823364645243: 100% 332/332 [00:07<00:00, 41.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8.614323 --> 8.043051).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:39 loss:0.000587772810831666: 100% 332/332 [00:07<00:00, 42.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (8.043051 --> 7.722434).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:40 loss:0.02013399638235569: 100% 332/332 [00:08<00:00, 40.74it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:41 loss:0.004812478553503752: 100% 332/332 [00:07<00:00, 42.32it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:42 loss:0.00087630411144346: 100% 332/332 [00:07<00:00, 42.23it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:43 loss:0.0006485601188614964: 100% 332/332 [00:07<00:00, 42.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (7.722434 --> 7.606612).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:44 loss:0.0006030846852809191: 100% 332/332 [00:07<00:00, 41.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (7.606612 --> 6.753297).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:45 loss:0.00019836111459881067: 100% 332/332 [00:07<00:00, 41.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:46 loss:0.33788612484931946: 100% 332/332 [00:07<00:00, 42.53it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:47 loss:0.016432758420705795: 100% 332/332 [00:07<00:00, 42.30it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:48 loss:0.0030084478203207254: 100% 332/332 [00:07<00:00, 42.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:49 loss:0.0004936078912578523: 100% 332/332 [00:07<00:00, 42.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch:50 loss:3.8890138966962695e-05: 100% 332/332 [00:07<00:00, 42.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# early_stopping 객체 선언(3번의 epoch 연속으로 loss 미개선 시에 조기 종료 예시)\n",
    "early_stopping = EarlyStopping(patience = 10, verbose = True)\n",
    "\n",
    "for epoch in range(50):\n",
    "    ### 각 epoch의 train 부분 ###\n",
    "    model.train()\n",
    "    val_loss = 0\n",
    "    iterator = tqdm.tqdm(train_loader)\n",
    "    for data, label in iterator:\n",
    "        # 최적화를 위해 기울기를 초기화\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # 모델의 예측값\n",
    "        preds = model(data.to(device))\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "\n",
    "        iterator.set_description(f\"train epoch:{epoch+1} loss:{loss.item()}\")\n",
    "        \n",
    "    ### 각 epoch train 이후 evaluation 진행 ###\n",
    "    model.eval()\n",
    "    \n",
    "    ### early stopping 여부를 체크하는 부분 ###\n",
    "    early_stopping(val_loss, model) # 현재 과적합 상황 추적\n",
    "    \n",
    "    if early_stopping.early_stop: # 조건 만족 시 조기 종료\n",
    "        break\n",
    "\n",
    "torch.save(model.state_dict(), \"ResNet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75b7a219-0a64-4b05-bc43-569c4eae8efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.37349397590361444\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"checkpoint.pt\", map_location=device))\n",
    "\n",
    "num_corr = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in valid_loader:\n",
    "        output = model(data.to(device))\n",
    "        #torch.Size([3, 64, 64])\n",
    "        #print(data.to(device)[0].shape)\n",
    "        #print(label, output.data.max(1)[1])\n",
    "        preds = output.data.max(1)[1]\n",
    "        corr = preds.eq(label.to(device).data).sum().item()\n",
    "        #correct += preds.eq(label.to(device).view_as(preds)).sum().item()  # target, pred 일치하는 값의 개수\n",
    "        num_corr += corr\n",
    "\n",
    "    print(f\"Accuracy:{num_corr/(len(valid_loader)*bs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
